{
  "manifest": {
    "name": "@discoveryjs/json-ext",
    "version": "0.6.3",
    "description": "A set of utilities that extend the use of JSON",
    "keywords": [
      "json",
      "utils",
      "stream",
      "async",
      "promise",
      "stringify",
      "info"
    ],
    "author": {
      "name": "Roman Dvornov",
      "email": "rdvornov@gmail.com",
      "url": "https://github.com/lahmatiy"
    },
    "license": "MIT",
    "repository": {
      "type": "git",
      "url": "git+https://github.com/discoveryjs/json-ext.git"
    },
    "engines": {
      "node": ">=14.17.0"
    },
    "type": "module",
    "main": "./cjs/index.cjs",
    "module": "./src/index.js",
    "types": "./index.d.ts",
    "exports": {
      ".": {
        "types": "./index.d.ts",
        "require": "./cjs/index.cjs",
        "import": "./src/index.js"
      },
      "./dist/*": "./dist/*",
      "./package.json": "./package.json"
    },
    "scripts": {
      "test": "npm run test:src",
      "lint": "eslint src",
      "lint-and-test": "npm run lint && npm test",
      "bundle": "node scripts/bundle.js",
      "transpile": "node scripts/transpile.cjs",
      "test:all": "npm run test:src && npm run test:cjs && npm run test:dist && npm run test:e2e",
      "test:src": "mocha --reporter progress src/*.test.js",
      "test:cjs": "mocha --reporter progress cjs/*.test.cjs",
      "test:e2e": "mocha --reporter progress test-e2e",
      "test:dist": "mocha --reporter progress dist/test",
      "test:deno": "node scripts/deno-adapt-test.js && mocha --reporter progress deno-tests/*.test.js",
      "bundle-and-test": "npm run bundle && npm run test:dist",
      "coverage": "c8 --reporter=lcovonly npm test",
      "prepublishOnly": "npm run lint && npm run bundle && npm run transpile && npm run test:all"
    },
    "devDependencies": {
      "c8": "^7.10.0",
      "chalk": "^4.1.0",
      "esbuild": "^0.24.0",
      "eslint": "^8.57.0",
      "mocha": "^9.2.2",
      "rollup": "^2.79.2"
    },
    "files": [
      "cjs",
      "!cjs/*{.test,-cases}.cjs",
      "dist",
      "src",
      "!src/*{.test,-cases}.js",
      "index.d.ts"
    ],
    "_registry": "npm",
    "_loc": "/home/dev/api_maker/.yarn-cache/v6/npm-@discoveryjs-json-ext-0.6.3-f13c7c205915eb91ae54c557f5e92bddd8be0e83-integrity/node_modules/@discoveryjs/json-ext/package.json",
    "readmeFilename": "README.md",
    "readme": "# json-ext\n\n[![NPM version](https://img.shields.io/npm/v/@discoveryjs/json-ext.svg)](https://www.npmjs.com/package/@discoveryjs/json-ext)\n[![Build Status](https://github.com/discoveryjs/json-ext/actions/workflows/ci.yml/badge.svg)](https://github.com/discoveryjs/json-ext/actions/workflows/ci.yml)\n[![Coverage Status](https://coveralls.io/repos/github/discoveryjs/json-ext/badge.svg?branch=master)](https://coveralls.io/github/discoveryjs/json-ext)\n[![NPM Downloads](https://img.shields.io/npm/dm/@discoveryjs/json-ext.svg)](https://www.npmjs.com/package/@discoveryjs/json-ext)\n\nA set of utilities designed to extend JSON's capabilities, especially for handling large JSON data (over 100MB) efficiently:\n\n- [parseChunked()](#parsechunked) – Parses JSON incrementally; similar to [`JSON.parse()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse), but processing JSON data in chunks.\n- [stringifyChunked()](#stringifychunked) – Converts JavaScript objects to JSON incrementally; similar to [`JSON.stringify()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify), but returns a generator that yields JSON strings in parts.\n- [stringifyInfo()](#stringifyinfo) – Estimates the size of the `JSON.stringify()` result and identifies circular references without generating the JSON.\n- [parseFromWebStream()](#parsefromwebstream) – A helper function to parse JSON chunks directly from a Web Stream.\n- [createStringifyWebStream()](#createstringifywebstream) – A helper function to generate JSON data as a Web Stream.\n\n### Key Features\n\n- Optimized to handle large JSON data with minimal resource usage (see [benchmarks](./benchmarks/README.md))\n- Works seamlessly with browsers, Node.js, Deno, and Bun\n- Supports both Node.js and Web streams\n- Available in both ESM and CommonJS\n- TypeScript typings included\n- No external dependencies\n- Compact size: 9.4Kb (minified), 3.8Kb (min+gzip)\n\n### Why json-ext?\n\n- **Handles large JSON files**: Overcomes the limitations of V8 for strings larger than ~500MB, enabling the processing of huge JSON data.\n- **Prevents main thread blocking**: Distributes parsing and stringifying over time, ensuring the main thread remains responsive during heavy JSON operations.\n- **Reduces memory usage**: Traditional `JSON.parse()` and `JSON.stringify()` require loading entire data into memory, leading to high memory consumption and increased garbage collection pressure. `parseChunked()` and `stringifyChunked()` process data incrementally, optimizing memory usage.\n- **Size estimation**: `stringifyInfo()` allows estimating the size of resulting JSON before generating it, enabling better decision-making for JSON generation strategies.\n\n## Install\n\n```bash\nnpm install @discoveryjs/json-ext\n```\n\n## API\n\n### parseChunked()\n\nFunctions like [`JSON.parse()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse), iterating over chunks to reconstruct the result object, and returns a [Promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise).\n\n> Note: `reviver` parameter is not supported yet.\n\n```ts\nfunction parseChunked(input: Iterable<Chunk> | AsyncIterable<Chunk>): Promise<any>;\nfunction parseChunked(input: () => (Iterable<Chunk> | AsyncIterable<Chunk>)): Promise<any>;\n\ntype Chunk = string | Buffer | Uint8Array;\n```\n\n[Benchmark](https://github.com/discoveryjs/json-ext/tree/master/benchmarks#parse-chunked)\n\nUsage:\n\n```js\nimport { parseChunked } from '@discoveryjs/json-ext';\n\nconst data = await parseChunked(chunkEmitter);\n```\n\nParameter `chunkEmitter` can be an iterable or async iterable that iterates over chunks, or a function returning such a value. A chunk can be a `string`, `Uint8Array`, or Node.js `Buffer`.\n\nExamples:\n\n- Generator:\n    ```js\n    parseChunked(function*() {\n        yield '{ \"hello\":';\n        yield Buffer.from(' \"wor'); // Node.js only\n        yield new TextEncoder().encode('ld\" }'); // returns Uint8Array\n    });\n    ```\n- Async generator:\n    ```js\n    parseChunked(async function*() {\n        for await (const chunk of someAsyncSource) {\n            yield chunk;\n        }\n    });\n    ```\n- Array:\n    ```js\n    parseChunked(['{ \"hello\":', ' \"world\"}'])\n    ```\n- Function returning iterable:\n    ```js\n    parseChunked(() => ['{ \"hello\":', ' \"world\"}'])\n    ```\n- Node.js [`Readable`](https://nodejs.org/dist/latest-v14.x/docs/api/stream.html#stream_readable_streams) stream:\n    ```js\n    import fs from 'node:fs';\n\n    parseChunked(fs.createReadStream('path/to/file.json'))\n    ```\n- Web stream (e.g., using [fetch()](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)):\n    > Note: Iterability for Web streams was added later in the Web platform, not all environments support it. Consider using `parseFromWebStream()` for broader compatibility.\n    ```js\n    const response = await fetch('https://example.com/data.json');\n    const data = await parseChunked(response.body); // body is ReadableStream\n    ```\n\n### stringifyChunked()\n\nFunctions like [`JSON.stringify()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify), but returns a generator yielding strings instead of a single string.\n\n> Note: Returns `\"null\"` when `JSON.stringify()` returns `undefined` (since a chunk cannot be `undefined`).\n\n```ts\nfunction stringifyChunked(value: any, replacer?: Replacer, space?: Space): Generator<string, void, unknown>;\nfunction stringifyChunked(value: any, options: StringifyOptions): Generator<string, void, unknown>;\n\ntype Replacer =\n    | ((this: any, key: string, value: any) => any)\n    | (string | number)[]\n    | null;\ntype Space = string | number | null;\ntype StringifyOptions = {\n    replacer?: Replacer;\n    space?: Space;\n    highWaterMark?: number;\n};\n```\n\n[Benchmark](https://github.com/discoveryjs/json-ext/tree/master/benchmarks#stream-stringifying)\n\nUsage:\n\n- Getting an array of chunks:\n    ```js\n    const chunks = [...stringifyChunked(data)];\n    ```\n- Iterating over chunks:\n    ```js\n    for (const chunk of stringifyChunked(data)) {\n        console.log(chunk);\n    }\n    ```\n- Specifying the minimum size of a chunk with `highWaterMark` option:\n    ```js\n    const data = [1, \"hello world\", 42];\n\n    console.log([...stringifyChunked(data)]); // default 16kB\n    // ['[1,\"hello world\",42]']\n\n    console.log([...stringifyChunked(data, { highWaterMark: 16 })]);\n    // ['[1,\"hello world\"', ',42]']\n\n    console.log([...stringifyChunked(data, { highWaterMark: 1 })]);\n    // ['[1', ',\"hello world\"', ',42', ']']\n    ```\n- Streaming into a stream with a `Promise` (modern Node.js):\n    ```js\n    import { pipeline } from 'node:stream/promises';\n    import fs from 'node:fs';\n\n    await pipeline(\n        stringifyChunked(data),\n        fs.createWriteStream('path/to/file.json')\n    );\n    ```\n- Wrapping into a `Promise` streaming into a stream (legacy Node.js):\n    ```js\n    import { Readable } from 'node:stream';\n\n    new Promise((resolve, reject) => {\n        Readable.from(stringifyChunked(data))\n            .on('error', reject)\n            .pipe(stream)\n            .on('error', reject)\n            .on('finish', resolve);\n    });\n    ```\n- Writing into a file synchronously:\n    > Note: Slower than `JSON.stringify()` but uses much less heap space and has no limitation on string length\n    ```js\n    import fs from 'node:fs';\n\n    const fd = fs.openSync('output.json', 'w');\n\n    for (const chunk of stringifyChunked(data)) {\n        fs.writeFileSync(fd, chunk);\n    }\n\n    fs.closeSync(fd);\n    ```\n- Using with fetch (JSON streaming):\n    > Note: This feature has limited support in browsers, see [Streaming requests with the fetch API](https://developer.chrome.com/docs/capabilities/web-apis/fetch-streaming-requests)\n\n    > Note: `ReadableStream.from()` has limited [support in browsers](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/from_static), use [`createStringifyWebStream()`](#createstringifywebstream) instead.\n    ```js\n    fetch('http://example.com', {\n        method: 'POST',\n        duplex: 'half',\n        body: ReadableStream.from(stringifyChunked(data))\n    });\n    ```\n- Wrapping into `ReadableStream`:\n    > Note: Use `ReadableStream.from()` or [`createStringifyWebStream()`](#createstringifywebstream) when no extra logic is needed\n    ```js\n    new ReadableStream({\n        start() {\n            this.generator = stringifyChunked(data);\n        },\n        pull(controller) {\n            const { value, done } = this.generator.next();\n\n            if (done) {\n                controller.close();\n            } else {\n                controller.enqueue(value);\n            }\n        },\n        cancel() {\n            this.generator = null;\n        }\n    });\n    ```\n\n### stringifyInfo()\n\n```ts\nexport function stringifyInfo(value: any, replacer?: Replacer, space?: Space): StringifyInfoResult;\nexport function stringifyInfo(value: any, options?: StringifyInfoOptions): StringifyInfoResult;\n\ntype StringifyInfoOptions = {\n    replacer?: Replacer;\n    space?: Space;\n    continueOnCircular?: boolean;\n}\ntype StringifyInfoResult = {\n    bytes: number;      // size of JSON in bytes\n    spaceBytes: number; // size of white spaces in bytes (when space option used)\n    circular: object[]; // list of circular references\n};\n```\n\nFunctions like [`JSON.stringify()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify), but returns an object with the expected overall size of the stringify operation and a list of circular references.\n\nExample:\n\n```js\nimport { stringifyInfo } from '@discoveryjs/json-ext';\n\nconsole.log(stringifyInfo({ test: true }, null, 4));\n// {\n//   bytes: 20,     // Buffer.byteLength('{\\n    \"test\": true\\n}')\n//   spaceBytes: 7,\n//   circular: []    \n// }\n```\n\n#### Options\n\n##### continueOnCircular\n\nType: `Boolean`  \nDefault: `false`\n\nDetermines whether to continue collecting info for a value when a circular reference is found. Setting this option to `true` allows finding all circular references.\n\n### parseFromWebStream()\n\nA helper function to consume JSON from a Web Stream. You can use `parseChunked(stream)` instead, but `@@asyncIterator` on `ReadableStream` has limited support in browsers (see [ReadableStream](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream) compatibility table).\n\n```js\nimport { parseFromWebStream } from '@discoveryjs/json-ext';\n\nconst data = await parseFromWebStream(readableStream);\n// equivalent to (when ReadableStream[@@asyncIterator] is supported):\n// await parseChunked(readableStream);\n```\n\n### createStringifyWebStream()\n\nA helper function to convert `stringifyChunked()` into a `ReadableStream` (Web Stream). You can use `ReadableStream.from()` instead, but this method has limited support in browsers (see [ReadableStream.from()](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/from_static) compatibility table).\n\n```js\nimport { createStringifyWebStream } from '@discoveryjs/json-ext';\n\ncreateStringifyWebStream({ test: true });\n// equivalent to (when ReadableStream.from() is supported):\n// ReadableStream.from(stringifyChunked({ test: true }))\n```\n\n## License\n\nMIT\n",
    "licenseText": "MIT License\n\nCopyright (c) 2020-2024 Roman Dvornov <rdvornov@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/@discoveryjs/json-ext/-/json-ext-0.6.3.tgz#f13c7c205915eb91ae54c557f5e92bddd8be0e83",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/@discoveryjs/json-ext/-/json-ext-0.6.3.tgz",
    "hash": "f13c7c205915eb91ae54c557f5e92bddd8be0e83",
    "integrity": "sha512-4B4OijXeVNOPZlYA2oEwWOTkzyltLao+xbotHQeqN++Rv27Y6s818+n2Qkp8q+Fxhn0t/5lA5X1Mxktud8eayQ==",
    "registry": "npm",
    "packageName": "@discoveryjs/json-ext",
    "cacheIntegrity": "sha512-4B4OijXeVNOPZlYA2oEwWOTkzyltLao+xbotHQeqN++Rv27Y6s818+n2Qkp8q+Fxhn0t/5lA5X1Mxktud8eayQ== sha1-8Tx8IFkV65GuVMVX9ekr3di+DoM="
  },
  "registry": "npm",
  "hash": "f13c7c205915eb91ae54c557f5e92bddd8be0e83"
}